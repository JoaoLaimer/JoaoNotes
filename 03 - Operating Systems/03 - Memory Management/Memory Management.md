The management and arrangement are important factors in OS projects. One objective is to develop a OS that doesn't occupy too much memory and, at the same time, optimize its utilization.
A desirable memory has too be big, fast, non-volatile and low cost.

#### Memory Hierarchy
Secondary Memory -> Main Memory -> Cache -> Registers
Higher Capacity -------------------------- Lower Capacity
Slower --------------------------------------------- Faster

A memory manager must know which parts of the memory are being used and which are not. Allocate memory when processes needs, and free memory when processes are terminated.
Some requisites must be satisfied for a good memory architecture:
- Reallocation
- Protection
- Sharing
- Logical Arrangement
- Physical Arrangement

### Reallocation
A programmer must not worry about memory addressing and where the program is being loaded. During execution a process can exit the main memory and when it returns to it, it must be allocated elsewhere. 
A system must be able to translate the references to the memory found on the program's code to physical addresses, taking in consideration the location of the program on the main memory.

**Problem**: No memory abstraction.
**Solution**: Using an memory abstraction where each process possess its own addressing space defined by a _base register_ and a _limit_.
Each time the process references the memory, the hardware adds the base value to the address generated by the process.
Ex: Base Register: 16384
 JMP 28 -> JMP (16384 + 28) = 16412

### Protection
Processes can't reference areas of memory of another processes without permission. All memory references must be checked in execution time. Using the previous solution, if the referenced value is outside the defined interval the access is aborted.

### Sharing
Protection mechanism must be flexible to allow multiple processes to share the same area of memory. Processes the cooperate in any task can share the same data.

### Logical Arrangement
Programs normally are separated in modules, that can be written and compiled separately. 
If the hardware and OS manage programs as modules, some advantages can be obtained:
- Modules can be written and compiled independently and references to a module to another can be resolved in execution time.
- Different levels of protection can be introduced to modules.
- Sharing of modules, with the advantages can be defined by the user.

### Physical Arrangement
The memory is arranged as a hierarchy, the flux of information between the main memory and secondary memory is of great importance to the development of a memory managing system. If a program needs more than the available memory in the main memory, the secondary memory must be used (modules must be brought from and taken out of the secondary memory. This management is done by the OS.

## Managing Memory
Memory managing systems can be divided in two classes:
- 1) Systems that, during execution, bring and take processes between main memory and disk (process exchange and paging).
- 2) Simple systems, that can't exchange processes and do paging.

#### Simple Contiguous Allocation (The Simpler One)
The memory is divided into two parts: one for the OS and another to users programs.
A) Initially used in large computing units. Not used on minicomputers.
B) Used in hand computers (palmtop) and in embedded systems.
C) Was used on the first personal computers (MS-DOS), in which part of the system was contained in the ROM denominated BIOS (basic input output system).

This architecture is easy to implement, and doesn't allow the efficient use of the processor and the memory
- Only one program can be on the main memory at any time.
- If a user program doesn't fill all the memory, the memory will be underutilized.

User programs where limited by the size of the main memory, a solution proposed was dividing the program into modules that could be executed independently, using the sabe area of memory (overlay)

### Overlay
Suppose a program with a the following modules: main module, addressing, and impression.
The addressing module and impression are independent.
The size of the memory is insufficient to store all the program, the main module must reside in the memory for all execution time.
The overlay technique uses a common memory area to the addressing and impression modules.

Each time a module must referenced by the main module, it is loaded to the main memory. The overlay will have the size of the biggest module. This allows the programmer to "expand" the limits of the main memory.

This technique can lead to an excessive exchange of modules if not used carefully.

#### Multiprogramming Model
If a process stays has the CPU for only 20% of the time that it resides in the memory, with 5 processes we would use all the CPU (Optimistic and unreal).
A better approach, is to consider the CPU, in a probabilistic way. Suposse that a process wastes a fraction (p) of it's time, waiting I/O. With (n) processes, the probability of all (n) processes are waiting for I/O (CPU empty) it's p^n.
With that said, the utilization is: CPU usage = 1 - p^n.

While the memory possess a suficient number of jobs to guarantee to maintain the CPU busy all the time, there would be no reason to use any other complicated technique. But how?
The memory can be divided in parts (partitions):
- Static Allocation: Same size partitions or Different size partitions.
- Dynamic Allocation.

### Partitioned Static Allocation
In the first systems the memory was divided in fixed sizes. Each size was defined in the initialization of the system, if it has necessary to change the size of the partitions, the system would have to be reconfigured and rebooted.

#### Fixed Sized
Smaller sized processes than the partition size can be loaded in any available partition.
Two disadvantages:
- 1. If a program is too big to be allocated in any partition, it has to use the overlay technique.
- 2. if a program is too small, it will occupy an entire partition.
Memory wastage is called internal fragmentation.

#### Variable Sized 
Those two disadvantages can be minimized using variable partition sizes.
- Bigger programs can be allocated into bigger partitions.
- Smaller programs can be allocated into smaller partitions.
A strategy must be used to choose the partition.
- Using a process queue to each partition: Associating a process to the smaller partition that it can be allocated. But, empty partitions can surge and also long queues.
- Using a single queue: Programs can be loaded/executed in any free partition in the system.

Those methods are simple and have a lower overhead which requires minimum work from the operating system. 
But there are disadvantages: Internal fragmentation, inefficient usage of memory, system reboot for changing partition sizes.

### Partitioned Dynamic Allocation
When a process is brought to memory, it'll be allocated a space that fits it.
Fragmentation in this case happens when programs are terminated leaving ever smaller gaps in memory.
- External Fragmentation
A solution to external fragmentation is compacting the memory, but that should be used because it takes a long time to compact all memory.

If the data area of a job could grow, how the allocation process would work?
-  If there is an available space adjacent to the process, it could use it.
- Otherwise, the process would have to be moved to a space that could fit it.
- Adjacent process could be moved to disk, to create available space.
- If a process can't grow and the swap memory is full, the process will have to wait or be terminated.
- If it is expected that most process grow during their execution, we could allocate an extra area.
	- However, when process are moved back to disk, only used memory should be transferred.

## Partition Choosing Strategies 
#### First Fit:
- Chooses the first freed block with size sufficient to fit the program.
- In this algorithm the free block list is ordered by addresses.
- Low complexity.
#### Best Fit:
- Chooses the best block (tightest block).
- The problem lays on the tendency of leaving non-contiguous smaller fragments.
- High complexity.
#### Worst Fit:
- Chooses the worst block (loosest block).
- The idea is leaving bigger spaces for other programs to use.
#### Quick Fit:
- Has separated lists for some of the most utilized block sizes.

## Free Space Management
#### Bit Maps
Memory is divided by allocation units. The lower the unit, the bigger the bit map.
If the unit is too large, the map will be smaller, but memory could be wasted in the last memory unit.
Searching in this technique could be slow.

#### Linked List
Has a list with freed/allocated memory shards, ordered ascending.
Each element has:
 - Flag signaling with it's freed or allocated.
 - The first address of the shard
 - The length of the shard.
 - The address of the next shard.

## Swapping
Sometimes a program can't be executed because the memory lacks space.
Swapping happens when a program is waiting for freed space, the OS must choose the process to be taken out of the main memory and taken to the disk (swap out)
When the process need to return to the main memory (swap in) it can continue executing like nothing happened.
- Swapping is essential to the existence of the dynamic reallocation.
- The reallocation register is used to store the initial address of the memory region where the program will be allocated.
- When there's a reference to a address, it's value will be summed to the data stored in the register.

## Virtual Memory
Sophisticated memory management technique.
Main and secondary memory are combined, giving the user the impression of a much bigger memory than the main memory.
The main concept here is separating the addressing made by the program from the physical address.

Managing huge processes, makes the OS split the program into tasks.

A program in a virtual environment makes reference to virtual addresses.
In the execution of the program, translation from virtual to physical happens, called mapping.

While the program is executed only part of its code resides on the main memory, the rest stays in the secondary memory till it's referenced.

Virtual addressing space has no direct relation to real addressing space, a program can make a reference to virtual addresses that are outside real space constraints.
### Mapping
In modern systems the translation of virtual addresses is made by the hardware with the OS. A hardware component called MMU (Memory Management Unit) is responsible for this. The MMU is activate when there's a reference to a virtual address. Each process has it's own virtual addressing space.
The translation mechanism must keep mapping tables exclusive to each process.
The system must reference the mapping table during the execution of the process.
A register is used to store the address of the current mapping table.
Those tables are used to map blocks of data, where the size of the block defines the number of entries in a mapping table.

