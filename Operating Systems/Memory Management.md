The management and arrangement are important factors in OS projects. One objective is to develop a OS that doesn't occupy too much memory and, at the same time, optimize its utilization.
A desirable memory has too be big, fast, non-volatile and low cost.

#### Memory Hierarchy
Secondary Memory -> Main Memory -> Cache -> Registers
Higher Capacity -------------------------- Lower Capacity
Slower --------------------------------------------- Faster

A memory manager must know which parts of the memory are being used and which are not. Allocate memory when processes needs, and free memory when processes are terminated.
Some requisites must be satisfied for a good memory architecture:
- Reallocation
- Protection
- Sharing
- Logical Arrangement
- Physical Arrangement

### Reallocation
A programmer must not worry about memory addressing and where the program is being loaded. During execution a process can exit the main memory and when it returns to it, it must be allocated elsewhere. 
A system must be able to translate the references to the memory found on the program's code to physical addresses, taking in consideration the location of the program on the main memory.

**Problem**: No memory abstraction.
**Solution**: Using an memory abstraction where each process possess its own addressing space defined by a _base register_ and a _limit_.
Each time the process references the memory, the hardware adds the base value to the address generated by the process.
Ex: Base Register: 16384
 JMP 28 -> JMP (16384 + 28) = 16412

### Protection
Processes can't reference areas of memory of another processes without permission. All memory references must be checked in execution time. Using the previous solution, if the referenced value is outside the defined interval the access is aborted.

### Sharing
Protection mechanism must be flexible to allow multiple processes to share the same area of memory. Processes the cooperate in any task can share the same data.

### Logical Arrangement
Programs normally are separated in modules, that can be written and compiled separately. 
If the hardware and OS manage programs as modules, some advantages can be obtained:
- Modules can be written and compiled independently and references to a module to another can be resolved in execution time.
- Different levels of protection can be introduced to modules.
- Sharing of modules, with the advantages can be defined by the user.

### Physical Arrangement
The memory is arranged as a hierarchy, the flux of information between the main memory and secondary memory is of great importance to the development of a memory managing system. If a program needs more than the available memory in the main memory, the secondary memory must be used (modules must be brought from and taken out of the secondary memory. This management is done by the OS.

## Managing Memory
Memory managing systems can be divided in two classes:
- 1) Systems that, during execution, bring and take processes between main memory and disk (process exchange and paging).
- 2) Simple systems, that can't exchange processes and do paging.

#### Simple Contiguous Allocation (The Simpler One)
The memory is divided into two parts: one for the OS and another to users programs.
A) Initially used in large computing units. Not used on minicomputers.
B) Used in hand computers (palmtop) and in embedded systems.
C) Was used on the first personal computers (MS-DOS), in which part of the system was contained in the ROM denominated BIOS (basic input output system).

This architecture is easy to implement, and doesn't allow the efficient use of the processor and the memory
- Only one program can be on the main memory at any time.
- If a user program doesn't fill all the memory, the memory will be underutilized.

User programs where limited by the size of the main memory, a solution proposed was dividing the program into modules that could be executed independently, using the sabe area of memory (overlay)

### Overlay
Suppose a program with a the following modules: main module, addressing, and impression.
The addressing module and impression are independent.
The size of the memory is insufficient to store all the program, the main module must reside in the memory for all execution time.
The overlay technique uses a common memory area to the addressing and impression modules.

Each time a module must referenced by the main module, it is loaded to the main memory. The overlay will have the size of the biggest module. This allows the programmer to "expand" the limits of the main memory.

This technique can lead to an excessive exchange of modules if not used carefully.

#### Multiprogramming Model
If a process stays has the CPU for only 20% of the time that it resides in the memory, with 5 processes we would use all the CPU (Optimistic and unreal).
A better approach, is to consider the CPU, in a probabilistic way. Suposse that a process wastes a fraction (p) of it's time, waiting I/O. With (n) processes, the probability of all (n) processes are waiting for I/O (CPU empty) it's p^n.
With that said, the utilization is: CPU usage = 1 - p^n.

While the memory possess a suficient number of jobs to guarantee to maintain the CPU busy all the time, there would be no reason to use any other complicated technique. But how?
The memory can be divided in parts (partitions):
- Static Allocation: Same size partitions or Different size partitions.
- Dynamic Allocation.

### Partitioned Static Allocation
In the first systems the memory was divided in fixed sizes. Each size was defined in the initialization of the system, if it has necessary to change the size of the partitions, the system would have to be reconfigured and rebooted.

#### Fixed Sized
Smaller sized processes than the partition size can be loaded in any available partition.
Two disadvantages:
- 1. If a program is too big to be allocated in any partition, it has to use the overlay technique.
- 2. if a program is too small, it will occupy an entire partition.
Memory wastage is called internal fragmentation.

#### Variable Sized 
Those two advantages can be minimized using variable partition sizes.
- Bigger programs can be allocated into bigger partitions.
- Smaller programs can be allocated into smaller partitions.
A strategy must be used to choose the partition.
- Using a process queue to each partition: Associating a process to the smaller partition that it can be allocated. But, empty partitions can surge and also long queues.
- Using a single queue: Programs can be loaded/executed in any free partition in the system.

Those methods are simple and have a lower overhead which requires minimum work from the operating system. 
But there are disadvantages: Internal fragmentation, inefficient usage of memory, system reboot for changing partition sizes.

### Partitioned Dynamic Allocation